{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 决策树\n",
    "### 一、算法简介\n",
    "决策树是一种经久不衰的机器学习算法，它采用分治策略（divide-and-conquer）来进行标签预测。\n",
    "\n",
    "每次迭代选定一种属性作为父节点，根据属性值将样本划分到各子节点中，直到样本分类完全或到达预定的迭代次数算法结束，并返回最后一次子节点预测结果作为模型输出。\n",
    "（第一次迭代的父节点被特别称作根节点，最后一次迭代的子节点被特别称作叶节点，其它衍生过程中的父子节点被称作内部节点）\n",
    "\n",
    "_*可见，决策树算法的核心在于找到使每次迭代划分样本尽可能属于同一类别的父节点属性*_\n",
    "\n",
    "\n",
    "### 二、划分效果评价方法\n",
    "\n",
    "决策树模型样本划分效果评价方法，至今已经历ID3、C4.5和CART三代发展。\n",
    "\n",
    "1. 1970年，最先被提出的ID3算法根据最大化信息增益（information gain）来选定迭代的父节点属性。\n",
    "\n",
    "*但在相同条件下，取值比较多的特征比取值少的特征信息增益大。*\n",
    "\n",
    "2. 所以，1993年提出C4.5算法，使用增益率（gain rate）来选择最优划分属性，可以减少gain偏好更多取值特征带来的不利影响。\n",
    "\n",
    "同时，gain rate则会对可取值数目较少的属性有所偏好，因此C4.5算法使用一种启发式特征选择方法：\n",
    "**首先从候选属性中找出 information gain 高于平均水平的属性，然后在这些属性中找出 gain rate 最高的作为划分属性。**\n",
    "\n",
    "3. CART与ID3以及C4.5不同，它使用基尼系数（gini coefficien）对属性进行选则，是一个纯粹的二叉树，可用于分类也可用于回归。\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import warnings\n",
    "InteractiveShell.ast_node_interactivity = \"all\"  # 执行全部行输出命令\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "from sklearn.datasets import load_boston\n",
    "data = load_boston()\n",
    "df = pd.DataFrame(data['data'],columns=data['feature_names'])\n",
    "df['target']=data['target']\n",
    "df.info(); df.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "算法规划：\n",
    "1. 衡量指标计算函数\n",
    "2. 数据集分割函数\n",
    "3. 树生成函数\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 一、指标定义"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# 类别概率\n",
    "from collections import Counter\n",
    "def ProbE(e,elements):\n",
    "    return Counter(elements)[e]/len(elements)\n",
    "\n",
    "# 基尼系数\n",
    "def gini(elements):\n",
    "    return 1-np.sum(ProbE(e,elements)**2 for e in set(elements))\n",
    "\n",
    "# 信息熵\n",
    "def entropy(elements):\n",
    "    return -np.sum(ProbE(e,elements)*np.log2(ProbE(e,elements)) for e in set(elements))\n",
    "\n",
    "# 误差平方和，回归树使用\n",
    "def mse(elements):\n",
    "    return np.sum((e-np.mean(elements))**2 for e in elements)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 二、子集划分"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# 二叉树子集划分\n",
    "def SamplesSplit(df,feature,divide):\n",
    "    if df[feature].dtype=='object':\n",
    "        LeftSet = df[df[feature]==divide]\n",
    "        RightSet= df[~(df[feature]==divide)]\n",
    "    else:\n",
    "        LeftSet = df[df[feature]>=divide]\n",
    "        RightSet= df[~(df[feature]>=divide)]\n",
    "    return LeftSet,RightSet\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 三、树生成\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "# 评分\n",
    "def DivideScore(df,feature,fun,fv):\n",
    "    \"\"\"\n",
    "    默认输入数据集中，label在最后一列\n",
    "    \"\"\"\n",
    "    LeftSet,RightSet = SamplesSplit(df,feature,fv)\n",
    "    loss = LeftSet.shape[0]/df.shape[0]*fun(LeftSet.iloc[:,-1]) + RightSet.shape[0]/df.shape[0]*fun(RightSet.iloc[:,-1])\n",
    "    return loss\n",
    "\n",
    "# 选出特征最佳划分点\n",
    "def FeatureScore(df,feature,fun):\n",
    "    \"\"\"\n",
    "    Return the best divide and score.\n",
    "    \"\"\"\n",
    "    feature_values = sorted(set(df[feature]),reverse=False)\n",
    "    return sorted([(divide,DivideScore(df,feature,fun,divide)) for divide in feature_values],key=lambda x:x[1],reverse=False)[0]\n",
    "\n",
    "\n",
    "# 选出最佳特征\n",
    "def DivideFeatureSelect(df,fun):\n",
    "    \"\"\"\n",
    "    默认输入数据集中，label在最后一列\n",
    "    Return the best feature, divide and score.\n",
    "    \"\"\"\n",
    "    features = list(df.columns)[:-1]\n",
    "    return sorted([(feature,FeatureScore(df,feature,fun)) for feature in features],key=lambda x:x[2],reverse=False)[0]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "temp = DivideFeatureSelect(df,mse)\n",
    "temp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def Tree(train,epochs):\n",
    "    for i in range(epochs):\n",
    "        for j in range(2**i):\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
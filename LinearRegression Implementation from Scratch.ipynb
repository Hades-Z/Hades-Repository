{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 环境初始化\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"  # 执行全部行输出命令"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 数据准备"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "from sklearn.datasets import load_boston\n",
    "data = load_boston()\n",
    "print(data['DESCR'])\n",
    "# data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   ZN       506 non-null    float64\n",
      " 2   INDUS    506 non-null    float64\n",
      " 3   CHAS     506 non-null    float64\n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      506 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    float64\n",
      " 9   TAX      506 non-null    float64\n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    506 non-null    float64\n",
      " 13  target   506 non-null    float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 55.5 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n\n   PTRATIO       B  LSTAT  target  \n0     15.3  396.90   4.98    24.0  \n1     17.8  396.90   9.14    21.6  \n2     17.8  392.83   4.03    34.7  \n3     18.7  394.63   2.94    33.4  \n4     18.7  396.90   5.33    36.2  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CRIM</th>\n      <th>ZN</th>\n      <th>INDUS</th>\n      <th>CHAS</th>\n      <th>NOX</th>\n      <th>RM</th>\n      <th>AGE</th>\n      <th>DIS</th>\n      <th>RAD</th>\n      <th>TAX</th>\n      <th>PTRATIO</th>\n      <th>B</th>\n      <th>LSTAT</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00632</td>\n      <td>18.0</td>\n      <td>2.31</td>\n      <td>0.0</td>\n      <td>0.538</td>\n      <td>6.575</td>\n      <td>65.2</td>\n      <td>4.0900</td>\n      <td>1.0</td>\n      <td>296.0</td>\n      <td>15.3</td>\n      <td>396.90</td>\n      <td>4.98</td>\n      <td>24.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.02731</td>\n      <td>0.0</td>\n      <td>7.07</td>\n      <td>0.0</td>\n      <td>0.469</td>\n      <td>6.421</td>\n      <td>78.9</td>\n      <td>4.9671</td>\n      <td>2.0</td>\n      <td>242.0</td>\n      <td>17.8</td>\n      <td>396.90</td>\n      <td>9.14</td>\n      <td>21.6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.02729</td>\n      <td>0.0</td>\n      <td>7.07</td>\n      <td>0.0</td>\n      <td>0.469</td>\n      <td>7.185</td>\n      <td>61.1</td>\n      <td>4.9671</td>\n      <td>2.0</td>\n      <td>242.0</td>\n      <td>17.8</td>\n      <td>392.83</td>\n      <td>4.03</td>\n      <td>34.7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.03237</td>\n      <td>0.0</td>\n      <td>2.18</td>\n      <td>0.0</td>\n      <td>0.458</td>\n      <td>6.998</td>\n      <td>45.8</td>\n      <td>6.0622</td>\n      <td>3.0</td>\n      <td>222.0</td>\n      <td>18.7</td>\n      <td>394.63</td>\n      <td>2.94</td>\n      <td>33.4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.06905</td>\n      <td>0.0</td>\n      <td>2.18</td>\n      <td>0.0</td>\n      <td>0.458</td>\n      <td>7.147</td>\n      <td>54.2</td>\n      <td>6.0622</td>\n      <td>3.0</td>\n      <td>222.0</td>\n      <td>18.7</td>\n      <td>396.90</td>\n      <td>5.33</td>\n      <td>36.2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据集特征探索\n",
    "df = pd.DataFrame(data['data'],columns=data['feature_names'])\n",
    "df['target']=data['target']\n",
    "df.info(); df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 数据预处理\n",
    "1. 数值型特征与类别型特征分离\n",
    "2. 缺失值填充\n",
    "3. 重复值处理\n",
    "4. 异常值检测\n",
    "5. 类别型特征编码\n",
    "6. 数值型特征Normalization\n",
    "7. 特征衍生与降维（可选）\n",
    "8. 特征筛选\n",
    "9. 数据集分割"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "# 数值型特征与类别型特征分离\n",
    "df_cat = df[['CHAS','RAD']].astype('int').astype('category')\n",
    "df_num = df.drop(columns=['CHAS','RAD','target'])\n",
    "# print(df_cat.shape); print(df_num.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 类别型特征编码主要有 ordinal encoding 和 one-hot encoding 两种方法\n",
    "\n",
    "1. ordinal encoding编码\n",
    "适用于处理类别间具有大小关系的顺序型类别特征，它按类别大小关系，给其赋予一个从1到n的正整数数值ID，将类别型特征转化成数值型哑变量。\n",
    "\n",
    "2. one-hot encoding\n",
    "适用于处理类别间不具有大小关系的分类型类别特征，它按特征值类别数量产生一个n维0-1稀疏向量，每种特征值由向量中对应维度为1、其它维度为0表示。\n",
    "**使得任意两不同类别的编码向量之差相等，使得模型学习时，可以对每种类别一直同仁。**\n",
    "\n",
    "3. 网传可以通过二进制编码的方法，转化分类型类别特征，得到与one-hot encoding同样的效果，并且向量维数少于one-hot、节省存储空间。\n",
    "**这种说法是完全不对的，因为二进制编码与ordinal encoding的本质相同：编码向量间存在大小关系，任意不同类别编码向量间差值不等，模型学习时不能对特征的每种类别一视同仁**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "# 类别型特征编码\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot = OneHotEncoder()\n",
    "nar_cat = onehot.fit_transform(df_cat).toarray()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "             CRIM          ZN       INDUS         NOX          RM         AGE  \\\ncount  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \nmean     3.613524   11.363636   11.136779    0.554695    6.284634   68.574901   \nstd      8.601545   23.322453    6.860353    0.115878    0.702617   28.148861   \nmin      0.006320    0.000000    0.460000    0.385000    3.561000    2.900000   \n25%      0.082045    0.000000    5.190000    0.449000    5.885500   45.025000   \n50%      0.256510    0.000000    9.690000    0.538000    6.208500   77.500000   \n75%      3.677083   12.500000   18.100000    0.624000    6.623500   94.075000   \nmax     88.976200  100.000000   27.740000    0.871000    8.780000  100.000000   \n\n              DIS         TAX     PTRATIO           B       LSTAT  \ncount  506.000000  506.000000  506.000000  506.000000  506.000000  \nmean     3.795043  408.237154   18.455534  356.674032   12.653063  \nstd      2.105710  168.537116    2.164946   91.294864    7.141062  \nmin      1.129600  187.000000   12.600000    0.320000    1.730000  \n25%      2.100175  279.000000   17.400000  375.377500    6.950000  \n50%      3.207450  330.000000   19.050000  391.440000   11.360000  \n75%      5.188425  666.000000   20.200000  396.225000   16.955000  \nmax     12.126500  711.000000   22.000000  396.900000   37.970000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CRIM</th>\n      <th>ZN</th>\n      <th>INDUS</th>\n      <th>NOX</th>\n      <th>RM</th>\n      <th>AGE</th>\n      <th>DIS</th>\n      <th>TAX</th>\n      <th>PTRATIO</th>\n      <th>B</th>\n      <th>LSTAT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.613524</td>\n      <td>11.363636</td>\n      <td>11.136779</td>\n      <td>0.554695</td>\n      <td>6.284634</td>\n      <td>68.574901</td>\n      <td>3.795043</td>\n      <td>408.237154</td>\n      <td>18.455534</td>\n      <td>356.674032</td>\n      <td>12.653063</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>8.601545</td>\n      <td>23.322453</td>\n      <td>6.860353</td>\n      <td>0.115878</td>\n      <td>0.702617</td>\n      <td>28.148861</td>\n      <td>2.105710</td>\n      <td>168.537116</td>\n      <td>2.164946</td>\n      <td>91.294864</td>\n      <td>7.141062</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.006320</td>\n      <td>0.000000</td>\n      <td>0.460000</td>\n      <td>0.385000</td>\n      <td>3.561000</td>\n      <td>2.900000</td>\n      <td>1.129600</td>\n      <td>187.000000</td>\n      <td>12.600000</td>\n      <td>0.320000</td>\n      <td>1.730000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.082045</td>\n      <td>0.000000</td>\n      <td>5.190000</td>\n      <td>0.449000</td>\n      <td>5.885500</td>\n      <td>45.025000</td>\n      <td>2.100175</td>\n      <td>279.000000</td>\n      <td>17.400000</td>\n      <td>375.377500</td>\n      <td>6.950000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.256510</td>\n      <td>0.000000</td>\n      <td>9.690000</td>\n      <td>0.538000</td>\n      <td>6.208500</td>\n      <td>77.500000</td>\n      <td>3.207450</td>\n      <td>330.000000</td>\n      <td>19.050000</td>\n      <td>391.440000</td>\n      <td>11.360000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.677083</td>\n      <td>12.500000</td>\n      <td>18.100000</td>\n      <td>0.624000</td>\n      <td>6.623500</td>\n      <td>94.075000</td>\n      <td>5.188425</td>\n      <td>666.000000</td>\n      <td>20.200000</td>\n      <td>396.225000</td>\n      <td>16.955000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>88.976200</td>\n      <td>100.000000</td>\n      <td>27.740000</td>\n      <td>0.871000</td>\n      <td>8.780000</td>\n      <td>100.000000</td>\n      <td>12.126500</td>\n      <td>711.000000</td>\n      <td>22.000000</td>\n      <td>396.900000</td>\n      <td>37.970000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数值型特征描述性统计分析\n",
    "df_num.describe()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Normalization\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "# 数值型特征缩放\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "standardized = StandardScaler()\n",
    "nar_num = standardized.fit_transform(df_num)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "X = np.concatenate((nar_num, nar_cat), axis=1)\n",
    "y = data['target'].reshape(len(data['target']),1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "# 数据集分割\n",
    "def data_split(data, test_ratio=0.2, val_ratio=0, index=0):\n",
    "    if isinstance(index,int): index = np.random.choice(range(len(data)), size=len(data), replace=False)\n",
    "    train_index = index[:int(len(data)*(1-val_ratio-test_ratio))]\n",
    "    val_index = index[int(len(data)*(1-val_ratio-test_ratio)):int(len(data)*(1-test_ratio))]\n",
    "    test_index = index[int(len(data)*(1-test_ratio)):]\n",
    "    return data[train_index], data[test_index], data[val_index], index\n",
    "#\n",
    "X_train,X_test,_,X_index = data_split(X,test_ratio=0.2)\n",
    "y_train,y_test,_,y_index = data_split(y,test_ratio=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.21987621936163 47.70060686342776\n"
     ]
    }
   ],
   "source": [
    "# 模型定义\n",
    "def LinReg_train(X,y,num_epochs,lr):\n",
    "    num_sample,num_feature = X.shape\n",
    "    # 初始化\n",
    "    W = np.random.normal(0,1,(1,num_feature))\n",
    "    b = 0\n",
    "    loss=[0]\n",
    "    # 训练\n",
    "    for i in range(num_epochs):\n",
    "        y_hat = X.dot(W.T)+b\n",
    "        # MSE\n",
    "        ls = np.sum((y_hat-y)**2)/(2*num_sample)\n",
    "        # ls = (y_hat-y).dot((y_hat-y).T)/(2*num_sample)\n",
    "        loss.append(ls)\n",
    "        if abs(loss[-1]-loss[-2])<=0.001: return loss, W, b    # 已充分训练判定\n",
    "        # 优化（模型参数迭代）\n",
    "        W = W-lr*(y_hat-y).T.dot(X)/num_sample\n",
    "        b = b-lr*np.mean(y_hat-y)\n",
    "    return loss[1:], W, b\n",
    "\n",
    "# 预测\n",
    "def LinReg_price(X,y,W,b):\n",
    "    num_sample,_ = X.shape\n",
    "    y_hat = X.dot(W.T)+b\n",
    "    # MSE\n",
    "    ls = np.sum((y_hat-y)**2)/(2*num_sample)\n",
    "    # ls = (y_hat-y).dot((y_hat-y).T)/(2*num_sample)\n",
    "    return y_hat, ls\n",
    "\n",
    "# 训练\n",
    "Num=100\n",
    "ls=0\n",
    "loss_=0\n",
    "for _ in range(Num):\n",
    "    loss_CV,W,b = LinReg_train(X_train,y_train,1000000,0.01)\n",
    "    # 模型效果评估\n",
    "    ls+=loss_CV[-1]\n",
    "    #预测\n",
    "    y_hat,loss = LinReg_price(X_test,y_test,W,b)\n",
    "    loss_+=loss\n",
    "print(ls/Num, loss_/Num)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "#\n",
    "col_cat = ['CHAS'+str(i) for i in df_cat.CHAS.drop_duplicates()]+['RAD'+str(i) for i in df_cat.RAD.drop_duplicates()]\n",
    "col_num = list(df_num.columns)\n",
    "col = col_num + col_cat + ['target']\n",
    "df_rul = pd.DataFrame(np.concatenate((X, y), axis=1), columns=col)\n",
    "# df_rul.corr()['target'].sort_values(ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.4757241977359 45.72488318492\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((nar_num, df_rul[['RAD24']].values), axis=1)\n",
    "y = data['target'].reshape(len(data['target']),1)\n",
    "#\n",
    "X_train,X_test,_,_ = data_split(X,test_ratio=0.2,index=X_index)\n",
    "y_train,y_test,_,_ = data_split(y,test_ratio=0.2,index=y_index)\n",
    "#\n",
    "ls=0\n",
    "loss_=0\n",
    "for _ in range(Num):\n",
    "    loss_CV,W,b = LinReg_train(X_train,y_train,1000000,0.03)\n",
    "    # 模型效果评估\n",
    "    ls+=loss_CV[-1]\n",
    "    #预测\n",
    "    y_hat,loss = LinReg_price(X_test,y_test,W,b)\n",
    "    loss_+=loss\n",
    "print(ls/Num, loss_/Num)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.96333020786838 44.49434677548148\n"
     ]
    }
   ],
   "source": [
    "X = df_rul[['RM','PTRATIO','LSTAT']].values\n",
    "y = data['target'].reshape(len(data['target']),1)\n",
    "#\n",
    "X_train,X_test,_,_ = data_split(X,test_ratio=0.2,index=X_index)\n",
    "y_train,y_test,_,_ = data_split(y,test_ratio=0.2,index=y_index)\n",
    "#\n",
    "ls=0\n",
    "loss_=0\n",
    "for _ in range(Num):\n",
    "    loss_CV,W,b = LinReg_train(X_train,y_train,1000000,0.03)\n",
    "    # 模型效果评估\n",
    "    ls+=loss_CV[-1]\n",
    "    #预测\n",
    "    y_hat,loss = LinReg_price(X_test,y_test,W,b)\n",
    "    loss_+=loss\n",
    "print(ls/Num, loss_/Num)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-71aba385",
   "language": "python",
   "display_name": "PyCharm (Python Project)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
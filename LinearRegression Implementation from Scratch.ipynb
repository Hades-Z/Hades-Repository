{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Linear Regression\n",
    "#### 背景：\n",
    "线性回归是一种源自统计学的经典机器学习预测模型，它有解析求解和梯度下降优化两种解法，\n",
    "使用梯度下降优化的线性回归模型也是后续逻辑回归模型和深度学习全连网络实现的基石。\n",
    "\n",
    "#### 目的：\n",
    "1. 借助线性回归模型，探究主要数据预处理方法作用，及其对模型结果的影响\n",
    "2. 探究矩阵运算对模型计算效率的提升作用\n",
    "3. 探究模型过拟合的抑制方法和实用策略\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# 环境初始化\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"  # 执行全部行输出命令"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 数据准备\n",
    "浏览数据集描述信息后发现：\n",
    "1. 数据集一共有13个特征、506个样本，且数据集中没有缺失数据；\n",
    "2. 13个特征中，数值型特征11个，类别型特征2个（CHAS,RAD）"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "from sklearn.datasets import load_boston\n",
    "data = load_boston()\n",
    "print(data['DESCR'])\n",
    "# data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   ZN       506 non-null    float64\n",
      " 2   INDUS    506 non-null    float64\n",
      " 3   CHAS     506 non-null    float64\n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      506 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    float64\n",
      " 9   TAX      506 non-null    float64\n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    506 non-null    float64\n",
      " 13  target   506 non-null    float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 55.5 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n\n   PTRATIO       B  LSTAT  target  \n0     15.3  396.90   4.98    24.0  \n1     17.8  396.90   9.14    21.6  \n2     17.8  392.83   4.03    34.7  \n3     18.7  394.63   2.94    33.4  \n4     18.7  396.90   5.33    36.2  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CRIM</th>\n      <th>ZN</th>\n      <th>INDUS</th>\n      <th>CHAS</th>\n      <th>NOX</th>\n      <th>RM</th>\n      <th>AGE</th>\n      <th>DIS</th>\n      <th>RAD</th>\n      <th>TAX</th>\n      <th>PTRATIO</th>\n      <th>B</th>\n      <th>LSTAT</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00632</td>\n      <td>18.0</td>\n      <td>2.31</td>\n      <td>0.0</td>\n      <td>0.538</td>\n      <td>6.575</td>\n      <td>65.2</td>\n      <td>4.0900</td>\n      <td>1.0</td>\n      <td>296.0</td>\n      <td>15.3</td>\n      <td>396.90</td>\n      <td>4.98</td>\n      <td>24.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.02731</td>\n      <td>0.0</td>\n      <td>7.07</td>\n      <td>0.0</td>\n      <td>0.469</td>\n      <td>6.421</td>\n      <td>78.9</td>\n      <td>4.9671</td>\n      <td>2.0</td>\n      <td>242.0</td>\n      <td>17.8</td>\n      <td>396.90</td>\n      <td>9.14</td>\n      <td>21.6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.02729</td>\n      <td>0.0</td>\n      <td>7.07</td>\n      <td>0.0</td>\n      <td>0.469</td>\n      <td>7.185</td>\n      <td>61.1</td>\n      <td>4.9671</td>\n      <td>2.0</td>\n      <td>242.0</td>\n      <td>17.8</td>\n      <td>392.83</td>\n      <td>4.03</td>\n      <td>34.7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.03237</td>\n      <td>0.0</td>\n      <td>2.18</td>\n      <td>0.0</td>\n      <td>0.458</td>\n      <td>6.998</td>\n      <td>45.8</td>\n      <td>6.0622</td>\n      <td>3.0</td>\n      <td>222.0</td>\n      <td>18.7</td>\n      <td>394.63</td>\n      <td>2.94</td>\n      <td>33.4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.06905</td>\n      <td>0.0</td>\n      <td>2.18</td>\n      <td>0.0</td>\n      <td>0.458</td>\n      <td>7.147</td>\n      <td>54.2</td>\n      <td>6.0622</td>\n      <td>3.0</td>\n      <td>222.0</td>\n      <td>18.7</td>\n      <td>396.90</td>\n      <td>5.33</td>\n      <td>36.2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据集特征探索\n",
    "df = pd.DataFrame(data['data'],columns=data['feature_names'])\n",
    "df['target']=data['target']\n",
    "df.info(); df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 数据预处理\n",
    "1. 数值型特征与类别型特征分离\n",
    "2. 缺失值填充\n",
    "3. 重复值处理\n",
    "4. 异常值检测\n",
    "5. 类别型特征编码\n",
    "6. 数值型特征转换\n",
    "7. 特征衍生与降维（可选）\n",
    "8. 特征筛选（慎重）\n",
    "9. 数据集分割"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# 数值型特征与类别型特征分离\n",
    "df_cat = df[['CHAS','RAD']].astype('int').astype('category')\n",
    "df_num = df.drop(columns=['CHAS','RAD','target'])\n",
    "# print(df_cat.shape); print(df_num.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 类别型特征编码主要有 ordinal encoding 和 one-hot encoding 两种方法\n",
    "\n",
    "1. ordinal encoding编码\n",
    "适用于处理类别间具有大小关系的顺序型类别特征，它按类别大小关系，给其赋予一个从1到n的正整数数值ID，将类别型特征转化成数值型哑变量。\n",
    "\n",
    "2. one-hot encoding\n",
    "适用于处理类别间不具有大小关系的分类型类别特征，它按特征值类别数量产生一个n维0-1稀疏向量，每种特征值由向量中对应维度为1、其它维度为0表示。\n",
    "**使得任意两不同类别的编码向量之差相等，使得模型学习时，可以对每种类别一直同仁。**\n",
    "\n",
    "3. 网传可以通过二进制编码的方法，转化分类型类别特征，得到与one-hot encoding同样的效果，并且向量维数少于one-hot、节省存储空间。\n",
    "**这种说法是完全不对的，因为二进制编码与ordinal encoding的本质相同：编码向量间存在大小关系，任意不同类别编码向量间差值不等，模型学习时不能对特征的每种类别一视同仁**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# 类别型特征编码\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot = OneHotEncoder()\n",
    "nar_cat = onehot.fit_transform(df_cat).toarray()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "             CRIM          ZN       INDUS         NOX          RM         AGE  \\\ncount  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \nmean     3.613524   11.363636   11.136779    0.554695    6.284634   68.574901   \nstd      8.601545   23.322453    6.860353    0.115878    0.702617   28.148861   \nmin      0.006320    0.000000    0.460000    0.385000    3.561000    2.900000   \n25%      0.082045    0.000000    5.190000    0.449000    5.885500   45.025000   \n50%      0.256510    0.000000    9.690000    0.538000    6.208500   77.500000   \n75%      3.677083   12.500000   18.100000    0.624000    6.623500   94.075000   \nmax     88.976200  100.000000   27.740000    0.871000    8.780000  100.000000   \n\n              DIS         TAX     PTRATIO           B       LSTAT  \ncount  506.000000  506.000000  506.000000  506.000000  506.000000  \nmean     3.795043  408.237154   18.455534  356.674032   12.653063  \nstd      2.105710  168.537116    2.164946   91.294864    7.141062  \nmin      1.129600  187.000000   12.600000    0.320000    1.730000  \n25%      2.100175  279.000000   17.400000  375.377500    6.950000  \n50%      3.207450  330.000000   19.050000  391.440000   11.360000  \n75%      5.188425  666.000000   20.200000  396.225000   16.955000  \nmax     12.126500  711.000000   22.000000  396.900000   37.970000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CRIM</th>\n      <th>ZN</th>\n      <th>INDUS</th>\n      <th>NOX</th>\n      <th>RM</th>\n      <th>AGE</th>\n      <th>DIS</th>\n      <th>TAX</th>\n      <th>PTRATIO</th>\n      <th>B</th>\n      <th>LSTAT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.613524</td>\n      <td>11.363636</td>\n      <td>11.136779</td>\n      <td>0.554695</td>\n      <td>6.284634</td>\n      <td>68.574901</td>\n      <td>3.795043</td>\n      <td>408.237154</td>\n      <td>18.455534</td>\n      <td>356.674032</td>\n      <td>12.653063</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>8.601545</td>\n      <td>23.322453</td>\n      <td>6.860353</td>\n      <td>0.115878</td>\n      <td>0.702617</td>\n      <td>28.148861</td>\n      <td>2.105710</td>\n      <td>168.537116</td>\n      <td>2.164946</td>\n      <td>91.294864</td>\n      <td>7.141062</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.006320</td>\n      <td>0.000000</td>\n      <td>0.460000</td>\n      <td>0.385000</td>\n      <td>3.561000</td>\n      <td>2.900000</td>\n      <td>1.129600</td>\n      <td>187.000000</td>\n      <td>12.600000</td>\n      <td>0.320000</td>\n      <td>1.730000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.082045</td>\n      <td>0.000000</td>\n      <td>5.190000</td>\n      <td>0.449000</td>\n      <td>5.885500</td>\n      <td>45.025000</td>\n      <td>2.100175</td>\n      <td>279.000000</td>\n      <td>17.400000</td>\n      <td>375.377500</td>\n      <td>6.950000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.256510</td>\n      <td>0.000000</td>\n      <td>9.690000</td>\n      <td>0.538000</td>\n      <td>6.208500</td>\n      <td>77.500000</td>\n      <td>3.207450</td>\n      <td>330.000000</td>\n      <td>19.050000</td>\n      <td>391.440000</td>\n      <td>11.360000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.677083</td>\n      <td>12.500000</td>\n      <td>18.100000</td>\n      <td>0.624000</td>\n      <td>6.623500</td>\n      <td>94.075000</td>\n      <td>5.188425</td>\n      <td>666.000000</td>\n      <td>20.200000</td>\n      <td>396.225000</td>\n      <td>16.955000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>88.976200</td>\n      <td>100.000000</td>\n      <td>27.740000</td>\n      <td>0.871000</td>\n      <td>8.780000</td>\n      <td>100.000000</td>\n      <td>12.126500</td>\n      <td>711.000000</td>\n      <td>22.000000</td>\n      <td>396.900000</td>\n      <td>37.970000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数值型特征描述性统计分析\n",
    "df_num.describe()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 数值型特征转换主要有Feature Scaling和Non-linear transformation两大类方法\n",
    "\n",
    "**Feature Scaling**\n",
    "\n",
    "标准化\n",
    "\n",
    "定义：对不同维度数值特征做线性变换，使得不同度量之间的特征具有可比性，它不改变原始数据的分布。\n",
    "\n",
    "常用方法：\n",
    "1. Normalization (min-max normalization)\n",
    "2. Standardization(Z-score normalization)\n",
    "\n",
    "Normalization是一个源于统计学的概念，它包含数据预处理中常说的Standardization和Normalization两个概念，它们都是Feature Scaling的一种方法。\n",
    "\n",
    "*特别注意的是，稀疏数据一般不要执行标准化转换，因为Normalization会将一个多数元素为0的稀疏向量转化成一个多数元素不为0的密集特征向量，这会给模型运算带来巨大的负担。*\n",
    "\n",
    "**Non-linear transformation**\n",
    "\n",
    "归一化\n",
    "\n",
    "定义：对不同维度数值特征做非线性变换，使各个特征维度对目标函数的影响权重一致，即将那些扁平分布的特征数据伸缩变换成类圆形分布，会改变原始数据的分布。\n",
    "\n",
    "常用方法：\n",
    "1. L2范数归一化\n",
    "2. 对数变换\n",
    "3. 指数变换"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# 数值型特征缩放\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "standardized = StandardScaler()\n",
    "nar_num = standardized.fit_transform(df_num)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 特征筛选"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "target     1.000000\nRM         0.695360\nZN         0.360445\nB          0.333461\nDIS        0.249929\nRAD7       0.190053\nRAD4       0.187356\nCHAS1      0.175260\nRAD3       0.167352\nRAD2       0.104444\nRAD6       0.092802\nRAD1       0.040453\nRAD8      -0.039411\nRAD5      -0.065711\nCHAS0     -0.175260\nAGE       -0.376955\nCRIM      -0.388305\nRAD24     -0.396297\nNOX       -0.427321\nTAX       -0.468536\nINDUS     -0.483725\nPTRATIO   -0.507787\nLSTAT     -0.737663\nName: target, dtype: float64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 特征线性相关性筛选\n",
    "col_cat = ['CHAS'+str(i) for i in df_cat.CHAS.drop_duplicates()]+['RAD'+str(i) for i in df_cat.RAD.drop_duplicates()]\n",
    "col_num = list(df_num.columns)\n",
    "col = col_num + col_cat + ['target']\n",
    "df_rul = pd.DataFrame(np.concatenate((nar_num, nar_cat, df[['target']].values), axis=1), columns=col)\n",
    "df_rul.corr()['target'].sort_values(ascending=False)\n",
    "\n",
    "# 获取标签数据集\n",
    "y = df_rul[['target']].values.reshape(len(data['target']),1)\n",
    "\n",
    "# 获取特征数据集1：保留全部特征\n",
    "X_all = df_rul.drop(columns='target').values\n",
    "\n",
    "# 获取特征数据集2：去除低相关性特征，保留中、高相关性特征\n",
    "X_lcM = np.concatenate((nar_num, df_rul[['RAD24']].values), axis=1)\n",
    "\n",
    "# 获取特征数据集3：仅保留高相关性特征\n",
    "X_lcH = df_rul[['RM','PTRATIO','LSTAT']].values\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 数据集分割"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 定义分割函数\n",
    "def data_split(data, test_ratio=0.2, val_ratio=0, index=0):\n",
    "    if isinstance(index,int): index = np.random.choice(range(len(data)), size=len(data), replace=False)\n",
    "    train_index = index[:int(len(data)*(1-val_ratio-test_ratio))]\n",
    "    val_index = index[int(len(data)*(1-val_ratio-test_ratio)):int(len(data)*(1-test_ratio))]\n",
    "    test_index = index[int(len(data)*(1-test_ratio)):]\n",
    "    return data[train_index], data[test_index], data[val_index], index\n",
    "#\n",
    "y_train,y_test,_,_ = data_split(y,test_ratio=0.2)\n",
    "X_all_train,X_all_test,_,X_index = data_split(X_all,test_ratio=0.2)\n",
    "X_lcM_train,X_lcM_test,_,_ = data_split(X_lcM,test_ratio=0.2,index=X_index)\n",
    "X_lcH_train,X_lcH_test,_,_ = data_split(X_lcH,test_ratio=0.2,index=X_index)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# 模型定义\n",
    "def LinReg_train(X,y,num_epochs,lr,lam,patient):\n",
    "    num_sample,num_feature = X.shape\n",
    "    # 初始化\n",
    "    W_rec = [np.random.normal(0,1,(1,num_feature))]\n",
    "    b_rec = [0]\n",
    "    loss = [0]              # 每迭代损失函数值记录器\n",
    "    loss_diff = [np.inf]    # 每迭代损失函数下降步长记录器\n",
    "    j = 0                   # patient消耗程度记录器\n",
    "    # 训练\n",
    "    for i in range(num_epochs):\n",
    "        W = W_rec[i]; b = b_rec[i]\n",
    "        y_hat = X.dot(W.T)+b\n",
    "        # MSE & L2\n",
    "        # ls = float(np.sum((y_hat-y)**2)/(2*num_sample) + (lam/2)*W.dot(W.T))\n",
    "        ls = np.sum((y_hat-y)**2)/(2*num_sample)\n",
    "        # ls = (y_hat-y).dot((y_hat-y).T)/(2*num_sample)\n",
    "        loss.append(ls)\n",
    "        # 提前终止\n",
    "        loss_diff.append(float(abs(loss[-1]-loss[-2])))\n",
    "        if loss_diff[-1]>=min(loss_diff[:-1]): j+=1\n",
    "        if j==patient:\n",
    "            minLoss_index = loss.index(min(loss[1:]))\n",
    "            return loss[1:minLoss_index+1], W_rec[minLoss_index-1], b_rec[minLoss_index-1]\n",
    "        # 优化（GradientDescent & L2）\n",
    "        W = W-lr*(y_hat-y).T.dot(X)/num_sample - lr*lam*W\n",
    "        # W = W-lr*(y_hat-y).T.dot(X)/num_sample\n",
    "        b = b-lr*np.mean(y_hat-y)\n",
    "        W_rec.append(W); b_rec.append(b)\n",
    "    return loss[1:], W_rec[-1], b_rec[-1]\n",
    "\n",
    "# 预测\n",
    "def LinReg_price(X,y,W,b,lam):\n",
    "    num_sample,_ = X.shape\n",
    "    y_hat = X.dot(W.T)+b\n",
    "    # MSE\n",
    "    ls = np.sum((y_hat-y)**2)/(2*num_sample)\n",
    "    # ls = (y_hat-y).dot((y_hat-y).T)/(2*num_sample)\n",
    "    return y_hat, ls\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 抑制过拟合\n",
    "正则化和特征筛选是抑制过拟合的常用方法；\n",
    "\n",
    "其中，正则化常用实现方法有参数L2/L1范数惩罚和提前终止等，它们可以组合使用也可以单独使用。\n",
    "\n",
    "特征选择方法十分丰富，其目的是选出对预测标签最重要的一些特征，常用方法有线性相关性筛选、决策树/随机森林节点排序筛选和借助参数L1范数惩罚实现\n",
    "\n",
    "基于本项目的试验结果，综合来看过拟合抑制方法的推荐排序是首先使用提前终止和参数L2范数惩罚，如果效果能不满足要求再谨慎使用特征筛选。\n",
    "\n",
    "这是因为，提前终止没有需要校调的超参数，且在抑制过拟合的同时不会带来任何负面影响，但花无两样红，不得不说的是提前终止的过拟合抑制能力也远弱于另两种方法；\n",
    "\n",
    "另一方面，谨慎使用特征筛选的原因是，特征筛选会损失信息，同时本项目的试验结果显示，同时使用提前终止、参数惩罚时，特征筛选会增加一些模型预测结果的不稳定性（重复执行程序，针对不同随机抽样数据，模型评估指标波动程度增加）；\n",
    "\n",
    "通过合理设置参数L2范数惩罚项系数，可以在充分抑制过拟合的同时不损失特征信息、避免结果不稳定，所以结论：优先进行范数惩罚，最后再考虑特征筛选。\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.35803191764455 48.41191896736098\n",
      "40.36771704800768 48.4153703085966\n",
      "40.599942630414425 48.369638845968886\n"
     ]
    }
   ],
   "source": [
    "# 超参数定义\n",
    "num_epochs =1000000 #训练迭代次数\n",
    "lr = 0.03           #学习率\n",
    "lam = 10            #正则化惩罚系数\n",
    "patient = 10        #提前停止容忍度\n",
    "Num = 100          #重复试验次数\n",
    "\n",
    "#\n",
    "def Fun1(X_train,y_train,X_test,y_test,num_epochs,lr,lam,patient,Num):\n",
    "    # 初始化\n",
    "    ls=0; loss_=0\n",
    "    #\n",
    "    for _ in range(Num):\n",
    "        # 训练\n",
    "        loss_CV,W,b = LinReg_train(X_train,y_train,num_epochs,lr,lam,patient)\n",
    "        # 模型效果评估\n",
    "        ls+=loss_CV[-1]\n",
    "        # 预测\n",
    "        y_hat,loss = LinReg_price(X_test,y_test,W,b,3)\n",
    "        loss_+=loss\n",
    "    print(ls/Num, loss_/Num)\n",
    "\n",
    "# 全特征\n",
    "Fun1(X_all_train,y_train,X_all_test,y_test,num_epochs,lr,lam,patient,Num)\n",
    "# 中、高相关特征\n",
    "Fun1(X_lcM_train,y_train,X_lcM_test,y_test,num_epochs,lr,lam,patient,Num)\n",
    "# 仅含高相关特征\n",
    "Fun1(X_lcH_train,y_train,X_lcH_test,y_test,num_epochs,lr,lam,patient,Num)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-71aba385",
   "language": "python",
   "display_name": "PyCharm (Python Project)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}